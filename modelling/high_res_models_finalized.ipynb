{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7c5c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_helpers import *\n",
    "\n",
    "import cfgrib\n",
    "import xarray as xr\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyPhenology import models, utils\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from warnings import warn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "high_cutoff_year = 2022\n",
    "low_cutoff_year = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c9b1714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_df(train_df):\n",
    "    #print(train_df)\n",
    "    species_sites = train_df['site_id'].unique()\n",
    "        \n",
    "    #print(species_sites)\n",
    "    \n",
    "    site_ripenesses = []\n",
    "\n",
    "    for site in species_sites:\n",
    "        site_df = train_df[train_df['site_id'] == site]\n",
    "\n",
    "        site_ripenesses.append({\n",
    "            'site_id': site,\n",
    "            'doy': np.mean(site_df['doy'])\n",
    "        })\n",
    "\n",
    "    species_test_df = pd.DataFrame(site_ripenesses)\n",
    "    species_test_df['year'] = high_cutoff_year\n",
    "    \n",
    "    return species_test_df\n",
    "\n",
    "# More specific to our uses.\n",
    "def train_ripeness_small(observations, predictors, test_observations, test_predictors, model_name = 'ThermalTime'):\n",
    "\n",
    "    print(\"running model {m}\".format(m=model_name))\n",
    "    Model = utils.load_model(model_name)\n",
    "    model = Model()\n",
    "    model.fit(observations, predictors, optimizer_params='practical')\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    print(\"making predictions for model {m}\".format(m=model_name))        \n",
    "    preds = model.predict(test_observations, test_predictors)\n",
    "\n",
    "    print(preds)\n",
    "    test_days = test_observations.doy.values\n",
    "    print(test_days)\n",
    "    \n",
    "    # Various error types\n",
    "    model_mae = mae(test_days, preds)\n",
    "    model_rmse = rmse(test_days, preds)\n",
    "    median_error = np.median(np.abs(test_days - preds))\n",
    "\n",
    "    print('model {m} got a MAE of {a}'.format(m=model_name,a=model_mae))\n",
    "    print('model {m} got an RMSE of {a}'.format(m=model_name,a=model_rmse))\n",
    "    print('model {m}\\'s median error is: {a}'.format(m=model_name,a=median_error))\n",
    "\n",
    "    print(\"Ripeness Day: {}\".format(np.mean(preds)))\n",
    "    \n",
    "    ripeness_data = test_observations\n",
    "    ripeness_data['flowering_day'] = preds\n",
    "    \n",
    "    return ripeness_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd67a2",
   "metadata": {},
   "source": [
    "Idea for corrections: take the lower error between the base error and the year-transformed error.\n",
    "\n",
    "\n",
    "Best Approach is:\n",
    "- High time resolution, correcting for missing data by using averaged data from previous years.\n",
    "- Add European Weather data.\n",
    "- No southern hemisphere. \n",
    "- Corrected error (i.e. date wrapping). \n",
    "\n",
    "Best reporting statistic: what portion of results lie under X.\n",
    "For example, 80% of results lie under 1 STD, 95% lie under 2 STD. \n",
    "Can make a \"confidence score\" from this – percentile error? Ex. This is less error than 90% of things.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87c6b579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weather data\n",
      "Loading Plant Data\n",
      "filtering weather data\n",
      "formatting weather data\n",
      "formatting date columns\n",
      "correcting leap years\n",
      "adding site IDs to weather data\n",
      "separating weather data\n",
      "formatting plant data\n",
      "filtering plant data\n"
     ]
    }
   ],
   "source": [
    "# Load in high-res weather data\n",
    "print(\"loading weather data\")\n",
    "grib_data = cfgrib.open_datasets('../data/monthly_weather_data.grib')\n",
    "\n",
    "core_data = grib_data[0]\n",
    "\n",
    "print(\"Loading Plant Data\")\n",
    "formatted_plants = pd.read_csv(\"../data/model_training_data/all_plants_formatted.csv\", index_col=0)\n",
    "\n",
    "formatted_plants['rounded_lat'] = np.round(formatted_plants['latitude'], 1)\n",
    "formatted_plants['rounded_lon'] = np.round(formatted_plants['lon_360'], 1)\n",
    "\n",
    "rounded_sites = formatted_plants[['site_id', 'rounded_lat', 'rounded_lon']].drop_duplicates()\n",
    "\n",
    "site_x_vals = xr.DataArray(rounded_sites['rounded_lat'], dims=['site'])\n",
    "site_y_vals = xr.DataArray(rounded_sites['rounded_lon'], dims=['site'])\n",
    "\n",
    "print(\"filtering weather data\")\n",
    "full_weather_data = core_data.sel(latitude=site_x_vals, longitude=site_y_vals, method='nearest').to_dataframe().dropna()\n",
    "\n",
    "print(\"formatting weather data\")\n",
    "formatted_weather = format_weather_data(full_weather_data)\n",
    "\n",
    "formatted_weather['latitude'] = np.round(formatted_weather['latitude'], 1)\n",
    "formatted_weather['longitude'] = np.round(formatted_weather['longitude'], 1)\n",
    "\n",
    "print(\"adding site IDs to weather data\")\n",
    "rounded_sites['coordstring'] = rounded_sites['rounded_lat'].astype(str) + rounded_sites['rounded_lon'].astype(str)\n",
    "formatted_weather['coordstring'] = formatted_weather['latitude'].astype(str) + formatted_weather['longitude'].astype(str)\n",
    "\n",
    "## Add Site ID to the weather data\n",
    "weather_with_sites = pd.merge(formatted_weather, rounded_sites[['coordstring', 'site_id']], on='coordstring')#.drop('coordstring', axis=1)\n",
    "## Separate into training data and testing data\n",
    "\n",
    "# filter out current year\n",
    "print(\"separating weather data\")\n",
    "weather_with_sites = weather_with_sites[weather_with_sites['year'] != 2023]\n",
    "\n",
    "weather_training = weather_with_sites[weather_with_sites['year'] < high_cutoff_year]\n",
    "weather_test = weather_with_sites[weather_with_sites['year'] >= high_cutoff_year]\n",
    "\n",
    "# final formatting steps for plants\n",
    "print(\"formatting plant data\")\n",
    "species_list = formatted_plants['formatted_sci_name'].unique()\n",
    "formatted_plants.drop('species', axis=1, inplace=True)\n",
    "\n",
    "# correct for missing sites\n",
    "weather_sites = weather_with_sites['site_id'].unique()\n",
    "\n",
    "print(\"filtering plant data\")\n",
    "filtered_plants = formatted_plants[(formatted_plants['site_id'].isin(weather_sites)) & \n",
    "                                   (formatted_plants['year'] != 2023) &\n",
    "                                   (formatted_plants['latitude'] > 0) &\n",
    "                                    (formatted_plants['doy'] >= 60)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5a46fb",
   "metadata": {},
   "source": [
    "TODO: make the europe data rounded to .1 degrees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1048783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro_data = load_euro_weather_data(euro_path, '../data/high_res_euro_stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7b0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge both weather data. \n",
    "\n",
    "## If site is in europe data, replace it with the european version. \n",
    "\n",
    "# Create a list of \"mutual sites\".\n",
    "euro_coords = euro_data['coordstring'].unique()\n",
    "\n",
    "mutual_sites = weather_with_sites[weather_with_sites['coordstring'].isin(euro_coords)][['site_id', 'coordstring']].drop_duplicates()\n",
    "# Get those sites from europe\n",
    "mutual_sites_euro = euro_data[euro_data['coordstring'].isin(mutual_sites['coordstring'])]\n",
    "mutual_sites_euro = mutual_sites_euro.merge(mutual_sites, on='coordstring')\n",
    "\n",
    "mutual_sites_euro['temperature'] += 272.5\n",
    "\n",
    "# Remove those sites from monthly \n",
    "unmutual_monthly = weather_with_sites[~weather_with_sites['site_id'].isin(mutual_sites)]\n",
    "\n",
    "# rbind the two (a union essentially?)\n",
    "merged_euro = pd.concat([mutual_sites_euro, unmutual_monthly]).drop('station', axis=1).drop_duplicates()\n",
    "\n",
    "merged_euro['temperature'] = np.round(merged_euro['temperature'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a836435",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weather_training = merged_euro[merged_euro['year'] < high_cutoff_year]\n",
    "weather_test = merged_euro[merged_euro['year'] >= high_cutoff_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2fd1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                              | 0/97 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rubus\n",
      "running model ThermalTime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█▋                                                                                                                                                                    | 1/97 [00:03<05:30,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions for model ThermalTime\n",
      "[183 183 183 183 183 183 183 183 183 183 183 183 183 183 183 214 183 183\n",
      " 183 214 183 214 214 183 183 183 183 183 183 183]\n",
      "[183. 181. 190. 193. 165. 165. 184. 181. 178. 184. 246. 202. 288. 192.\n",
      " 173. 214. 159. 191. 191. 196. 187. 214. 216. 136. 305. 305. 305. 274.\n",
      " 191. 195.]\n",
      "model ThermalTime got a MAE of 28.6\n",
      "model ThermalTime got an RMSE of 49.24970389081881\n",
      "model ThermalTime's median error is: 9.5\n",
      "Ripeness Day: 187.13333333333333\n",
      "Rubus occidentalis\n",
      "running model ThermalTime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|███▍                                                                                                                                                                  | 2/97 [00:07<06:21,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions for model ThermalTime\n",
      "[183 183 183 183 183 183 214 214 214 183]\n",
      "[164. 189. 189. 189. 184. 189. 191. 191. 191. 187.]\n",
      "model ThermalTime got a MAE of 11.7\n",
      "model ThermalTime got an RMSE of 14.522396496446445\n",
      "model ThermalTime's median error is: 6.0\n",
      "Ripeness Day: 192.3\n",
      "Ficus\n",
      "running model ThermalTime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|█████▏                                                                                                                                                                | 3/97 [00:11<05:44,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions for model ThermalTime\n",
      "[245 245 245 245 245 245 245 245 245 245 245]\n",
      "[240. 210. 227. 229. 229. 248. 270. 270. 281. 239. 300.]\n",
      "model ThermalTime got a MAE of 21.818181818181817\n",
      "model ThermalTime got an RMSE of 26.460948928219075\n",
      "model ThermalTime's median error is: 18.0\n",
      "Ripeness Day: 245.0\n",
      "Ficus auriculata\n",
      "Ficus carica\n",
      "running model ThermalTime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████████▌                                                                                                                                                             | 5/97 [00:13<03:29,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions for model ThermalTime\n",
      "[245 245 245 275 275 245 245 245 245 245]\n",
      "[180. 232. 236. 278. 248. 258. 258. 248. 205. 335.]\n",
      "model ThermalTime got a MAE of 27.6\n",
      "model ThermalTime got an RMSE of 39.06404996924922\n",
      "model ThermalTime's median error is: 13.0\n",
      "Ripeness Day: 251.0\n",
      "Ficus citrifolia\n",
      "running model ThermalTime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██████████▎                                                                                                                                                           | 6/97 [00:18<04:42,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions for model ThermalTime\n",
      "[245 245]\n",
      "[201. 280.]\n",
      "model ThermalTime got a MAE of 39.5\n",
      "model ThermalTime got an RMSE of 39.75550276376844\n",
      "model ThermalTime's median error is: 39.5\n",
      "Ripeness Day: 245.0\n",
      "Ficus macrophylla\n",
      "running model ThermalTime\n"
     ]
    }
   ],
   "source": [
    "## Train models\n",
    "\n",
    "species_prediction_dict = {}\n",
    "\n",
    "for s in tqdm(species_list):\n",
    "    print(s)\n",
    "    species_train_df = filtered_plants.query('formatted_sci_name == \"{}\" and year < {}'.format(s, high_cutoff_year))\n",
    "    \n",
    "    if len(species_train_df) == 0:\n",
    "        continue\n",
    "    \n",
    "    species_test_df = filtered_plants.query('formatted_sci_name == \"{}\" and year >= {}'.format(s, high_cutoff_year))\n",
    "    \n",
    "   # print(species_train_df, species_test_df)\n",
    "    \n",
    "    if len(species_test_df) == 0:\n",
    "        # make predictions and compare to the mean ripeness day at each site\n",
    "        species_test_df = make_test_df(species_train_df)\n",
    "    \n",
    "    if len(species_test_df) == 0:\n",
    "        print(\"No test data for {}\".format(s))\n",
    "        #print(species_test_df)\n",
    "        \n",
    "    predictions = train_ripeness_small(species_train_df, weather_training,\n",
    "                        species_test_df, weather_test)\n",
    "    \n",
    "    species_prediction_dict[s] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5bf02c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyPhenology.models.thermaltime.ThermalTime object at 0x16af50ed0>\n",
      "making predictions for model ThermalTime\n"
     ]
    }
   ],
   "source": [
    "apple_train_df = filtered_plants[(filtered_plants['genus'] == 'Malus') & (filtered_plants['year'] < 2022)]\n",
    "apple_test_df = filtered_plants[(filtered_plants['genus'] == 'Malus') & (filtered_plants['year'] == 2022)]\n",
    "\n",
    "Model = utils.load_model('ThermalTime')\n",
    "model = Model()\n",
    "model.fit(apple_train_df, weather_training, optimizer_params='practical')\n",
    "\n",
    "print(model)\n",
    "\n",
    "print(\"making predictions for model {m}\".format(m='ThermalTime'))        \n",
    "preds = model.predict(apple_test_df, weather_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54adb074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245\n",
      " 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245\n",
      " 245 245 245 245 245 275 245 245 245 275 275 245 275 275 245 245 275 275\n",
      " 275 245 245 275 245 245 245 245 245 245 245 245 245 245 245 245 245 245\n",
      " 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245\n",
      " 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245\n",
      " 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245\n",
      " 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 275 245\n",
      " 245 245 245 275 245 245 245 245 245 245 245 245 245 245 275 275 275 245\n",
      " 245 245 245 245 245 275 275 275 245 245 245 245 245 245 275 245 245 245\n",
      " 245 245 245 245 245 275 245 245 245 245 245 245 245 245 245 245 245 245\n",
      " 275 245 245 245 245 245 245 275 245 245 245 245 245 245 245 245 275 275\n",
      " 275 275 275 245 245 245 245 245 245 245 245 245 245 245 245 245 245 275\n",
      " 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245 245\n",
      " 245 275 275 275 245 245 245 245 245 245 245 245 245 245 245 245 245 275\n",
      " 245 245 275 275 245 245 245 275 245 245 275 245 245 245 245]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2691fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_test_df = merged_euro[(merged_euro['site_id'].isin(apple_test_df['site_id'])) & (merged_euro['year'] == 2022)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f43eed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 275, 245, 245, 245, 275, 275, 245, 275, 275, 245, 245,\n",
       "       275, 275, 275, 245, 245, 275, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 275,\n",
       "       245, 245, 245, 245, 275, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 275, 275, 275, 245, 245, 245, 245, 245, 245, 275, 275,\n",
       "       275, 245, 245, 245, 245, 245, 245, 275, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 275, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 275, 245, 245, 245, 245, 245, 245, 275, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 275, 275, 275, 275, 275, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 275,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 275, 275, 275, 245, 245, 245, 245,\n",
       "       245, 245, 245, 245, 245, 245, 245, 245, 245, 275, 245, 245, 275,\n",
       "       275, 245, 245, 245, 275, 245, 245, 275, 245, 245, 245, 245])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(apple_test_df, weather_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9b73d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 185.64310747459587, 'T': 14.178133503486173, 'F': 574.1517057222219}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d59d1b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[313. 355. 334.  63. 191. 273. 270. 203. 231. 217. 252. 238. 224. 280.\n",
      " 259. 196. 210. 189. 295. 288. 302. 280. 342. 294. 348. 287. 308. 301.\n",
      " 324. 317. 333. 124. 288. 231. 266. 240. 282. 238. 246. 256. 253. 309.\n",
      " 309. 289. 321. 323. 304. 303. 288. 324. 297. 328. 316. 310. 302. 294.\n",
      " 316. 295. 301. 271. 277. 291. 310. 269. 264. 272. 284. 270. 253. 264.\n",
      " 282. 289. 275. 333. 293. 296. 325. 300. 309. 319. 315. 268.  63. 303.\n",
      " 173. 172. 243. 250. 257. 278. 285. 292. 264. 271. 311. 273. 342. 318.\n",
      " 301. 313. 280. 336. 308. 292. 306. 294. 283. 329. 285. 297. 324. 304.\n",
      " 274. 292. 290. 322. 298. 313. 319. 316. 326. 310. 306. 295. 266. 231.\n",
      " 222. 138. 250. 236. 323. 252. 236. 182. 186. 186. 186. 203. 295.  85.\n",
      " 178. 240. 234. 235. 257. 232. 235. 236. 235. 240. 233. 233. 240. 240.\n",
      " 241. 241. 241. 241. 242. 242. 242. 244. 243. 245. 246. 247. 247. 248.\n",
      " 248. 249. 248. 249. 250. 250. 251. 251. 251. 251. 215. 214. 216. 220.\n",
      " 225. 225. 225. 225. 225. 229. 229. 233. 215. 231. 231. 232. 232. 233.\n",
      " 233. 248. 249. 248. 242. 189. 234. 248. 259. 260. 261. 256. 262. 263.\n",
      " 245. 264. 264. 265. 266. 269. 267. 267. 267. 268. 268. 268. 281. 268.\n",
      " 263. 263. 272. 274. 275. 276. 278. 279. 280. 280. 277. 283. 283. 284.\n",
      " 284. 286. 280. 269. 294. 226. 302. 305. 298. 314. 315. 313. 245. 245.\n",
      " 252. 242. 253. 249. 254. 255. 256. 256. 255. 258. 258. 322. 322. 320.\n",
      " 338. 237. 248. 108. 251. 193. 245. 245. 264. 291. 259. 242. 225. 253.\n",
      " 266. 280. 280. 260. 278.]\n"
     ]
    }
   ],
   "source": [
    "#print(preds)\n",
    "test_days = apple_test_df.doy.values\n",
    "print(test_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c85c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_prediction_dict = {}\n",
    "\n",
    "for s in tqdm(filtered_plants['genus'].unique()):\n",
    "    print(s)\n",
    "    species_train_df = filtered_plants.query('genus == \"{}\" and year < {}'.format(s, high_cutoff_year))\n",
    "    \n",
    "    if len(species_train_df) == 0:\n",
    "        continue\n",
    "    \n",
    "    species_test_df = filtered_plants.query('genus == \"{}\" and year >= {}'.format(s, high_cutoff_year))\n",
    "    \n",
    "    if len(species_test_df) == 0:\n",
    "        # make predictions and compare to the mean ripeness day at each site\n",
    "        species_test_df = make_test_df(species_train_df)\n",
    "    \n",
    "    if len(species_test_df) == 0:\n",
    "        print(\"No test data for {}\".format(s))\n",
    "        #print(species_test_df)\n",
    "        \n",
    "    predictions = train_ripeness_small(species_train_df, weather_training,\n",
    "                        species_test_df, weather_test)\n",
    "    \n",
    "    genus_prediction_dict[s] = predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seasonality",
   "language": "python",
   "name": "seasonality"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
